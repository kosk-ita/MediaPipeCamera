import csv
from collections import Counter
from collections import deque
from utils import CvFpsCalc
import numpy as np
import cv2
from PIL import Image, ImageFont, ImageDraw

import emoji
import mediapipe as mp 

from kazuhito import *
from model import KeyPointClassifier
from funcs import validate_facerect


# ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸºåº•ã‚¯ãƒ©ã‚¹
class BaseDecoration():
    name = "Sample Name"
    description = "Sample Text."
    def decorate(self, input_image):
        return input_image

class MPFaceDecoration(BaseDecoration):
    name = "é¡”èªè­˜ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ MediaPipeç‰ˆ"
    description = "MediaPipeã‚’ç”¨ã„ã¦é¡”ã‚’æ¤œå‡ºã—ã€ã‚¢ã‚¤ã‚³ãƒ³ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚ã‚¢ã‚¤ã‚³ãƒ³ã«ç”¨ã„ã‚‹çµµæ–‡å­—ã¯è‡ªç”±ã«æŒ‡å®šã§ãã¾ã™ã€‚"
    
    def __init__(self, args=dict()):
        mp_face_detection = mp.solutions.face_detection
        self.face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)
        
        # çµµæ–‡å­—ç”»åƒã‚’ä¿å­˜ã™ã‚‹
        img = Image.new("RGB", (134,126), (0,0,0))
        draw = ImageDraw.Draw(img)
        font = ImageFont.truetype("./fonts/NotoColorEmoji.ttf", size=109, layout_engine=ImageFont.LAYOUT_RAQM)
        # tick = str(emoji.emojize(':grinning_face:'))
        if 'symbol' in args.keys():
            tick = args['symbol']
        else:
            tick = str(emoji.emojize(':grinning_face:'))
        draw.text((0, 0), tick, fill="#faa2",font=font, embedded_color=True)
        img.save("images/emoji/face_icon.png")
        self.icon = img
        
        self.im_p = None
    
    def decorate(self, input_image: np.ndarray) -> np.ndarray:
        """Pillowã‚’ä½¿ã£ã¦ã€é¡”ç”»åƒã‚’è²¼ã‚Šä»˜ã‘ã‚‹
        Args:
            input_image (np.ndarray): OpenCV image
        Returns:
            np.ndarray: OpenCV image
        """
        # çµæœã‚’æ ¼ç´ã™ã‚‹é…åˆ—
        deco_image = np.zeros_like(input_image)
        # çµæœã‚’æç”»ã™ã‚‹PillowImage
        self.im_p = Image.fromarray(deco_image)
        
        # é¡”æ¤œå‡º
        # input_image.flags.writable = False
        # image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
        results = self.face_detection.process(input_image)
        
        # æ¤œå‡ºã—ãŸé¡”ã«ã‚ã‚Œã™ã‚‹
        if results.detections:
            for detection in results.detections:
                x = detection.location_data.relative_bounding_box.xmin * self.im_p.width
                y = detection.location_data.relative_bounding_box.ymin * self.im_p.height
                h = detection.location_data.relative_bounding_box.height * self.im_p.height
                w = detection.location_data.relative_bounding_box.width * self.im_p.width
                x, y, h, w = validate_facerect(x, y, h, w)
                resized_icon = self.icon.resize((w, h))
                self.im_p.paste(resized_icon, (x, y))
                
        deco_image = np.array(self.im_p)
        return deco_image
    

class FruitLotteryDecoration(BaseDecoration):
    def __init__(self):
        self.use_brect = True
        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ #############################################################
        mp_hands = mp.solutions.hands
        self.hands = mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=1,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.5,
        )
        self.keypoint_classifier = KeyPointClassifier()
        
        # ãƒ•ãƒ«ãƒ¼ãƒ„æ±ºå®š
        self.random_fruit()
        
        # ãƒ©ãƒ™ãƒ«èª­ã¿è¾¼ã¿ ###########################################################
        with open('model/keypoint_classifier/keypoint_classifier_label.csv',
                encoding='utf-8-sig') as f:
            self.keypoint_classifier_labels = csv.reader(f)
            self.keypoint_classifier_labels = [
                row[0] for row in self.keypoint_classifier_labels
            ]

    def decorate(self, input_image: np.ndarray) -> np.ndarray:
        # image = input_image
        input_image.flags.writeable = False
        results = self.hands.process(input_image)
        input_image.flags.writeable = True
        
        # çµæœã‚’æç”»ã™ã‚‹é…åˆ—
        deco_image = np.zeros_like(input_image)
        # çµæœã‚’æç”»ã™ã‚‹PillowImage
        self.im_p = Image.fromarray(deco_image)
                
        if results.multi_hand_landmarks is not None:
            for hand_landmarks, handedness in zip(results.multi_hand_landmarks,
                                                  results.multi_handedness):
                # å¤–æ¥çŸ©å½¢ã®è¨ˆç®—
                brect = calc_bounding_rect(deco_image, hand_landmarks)
                # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®è¨ˆç®—
                landmark_list = calc_landmark_list(deco_image, hand_landmarks)

                # ç›¸å¯¾åº§æ¨™ãƒ»æ­£è¦åŒ–åº§æ¨™ã¸ã®å¤‰æ›
                pre_processed_landmark_list = pre_process_landmark(
                    landmark_list)
                
                # ãƒãƒ³ãƒ‰ã‚µã‚¤ãƒ³åˆ†é¡
                hand_sign_id = self.keypoint_classifier(pre_processed_landmark_list)
                if hand_sign_id == 0:  # ãƒ‘ãƒ¼
                    x, y, h, w = validate_facerect(brect['x'], brect['y'], brect['h'], brect['w'], mode='fruit')
                    resized_fruit = self.fruit.resize((w, h))
                    self.im_p.paste(resized_fruit, (x, y))
                    
                elif hand_sign_id == 1:  # ã‚°ãƒ¼
                    self.random_fruit()

                # æç”»
                # deco_image = draw_bounding_rect(self.use_brect, deco_image, brect)
                deco_image = draw_landmarks(deco_image, landmark_list)

        deco_image = np.array(self.im_p)
        return deco_image
    
    def random_fruit(self):
        # çµµæ–‡å­—ç”»åƒã‚’ä¿å­˜ã™ã‚‹
        img = Image.new("RGB", (134,126), (0,0,0))
        draw = ImageDraw.Draw(img)
        font = ImageFont.truetype("./fonts/NotoColorEmoji.ttf", size=109, layout_engine=ImageFont.LAYOUT_RAQM)
        # è¡¨ç¤ºã™ã‚‹æœç‰© ãƒ©ãƒ³ãƒ€ãƒ ã§æ±ºã¾ã‚‹
        fruits = list("ğŸ‡ğŸˆğŸ‰ğŸŠğŸ‹ğŸŒğŸ¥­ğŸğŸğŸğŸ‘ğŸ’ğŸ“ğŸ¥ğŸ…ğŸ†ğŸ¥”ğŸ¥•ğŸŒ½ğŸŒ¶ğŸ¥¦ğŸ§„ğŸ§…ğŸ„")
        tick = fruits[np.random.randint(len(fruits))]
        
        draw.text((0, 0), tick, fill="#faa2",font=font, embedded_color=True)
        img.save("images/emoji/fruit.png")
        self.fruit = img
        
class FingerDrawingDecoration(BaseDecoration):
    def __init__(self):
        self.use_brect = True
        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ #############################################################
        mp_hands = mp.solutions.hands
        self.hands = mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=1,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.5,
        )
        self.keypoint_classifier = KeyPointClassifier()
        # self.point_history_classifier = PointHistoryClassifier()
        
        # ãƒ©ãƒ™ãƒ«èª­ã¿è¾¼ã¿ ###########################################################
        with open('model/keypoint_classifier/keypoint_classifier_label.csv',
                encoding='utf-8-sig') as f:
            self.keypoint_classifier_labels = csv.reader(f)
            self.keypoint_classifier_labels = [
                row[0] for row in self.keypoint_classifier_labels
            ]

        # åº§æ¨™å±¥æ­´ #################################################################
        self.history_length = 64
        self.point_history = deque(maxlen=self.history_length)

        # ãƒ•ã‚£ãƒ³ã‚¬ãƒ¼ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼å±¥æ­´ ################################################
        self.finger_gesture_history = deque(maxlen=self.history_length)
        
    def decorate(self, input_image: np.ndarray) -> np.ndarray:
        # image = input_image
        input_image.flags.writeable = False
        results = self.hands.process(input_image)
        input_image.flags.writeable = True
        
        # çµæœã‚’æç”»ã™ã‚‹é…åˆ—
        debug_image = np.zeros_like(input_image)
        
        if results.multi_hand_landmarks is not None:
            for hand_landmarks, handedness in zip(results.multi_hand_landmarks,
                                                  results.multi_handedness):
                # å¤–æ¥çŸ©å½¢ã®è¨ˆç®—
                brect = calc_bounding_rect(debug_image, hand_landmarks)
                # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®è¨ˆç®—
                landmark_list = calc_landmark_list(debug_image, hand_landmarks)

                # ç›¸å¯¾åº§æ¨™ãƒ»æ­£è¦åŒ–åº§æ¨™ã¸ã®å¤‰æ›
                pre_processed_landmark_list = pre_process_landmark(
                    landmark_list)
                pre_processed_point_history_list = pre_process_point_history(
                    debug_image, self.point_history)

                # ãƒãƒ³ãƒ‰ã‚µã‚¤ãƒ³åˆ†é¡
                hand_sign_id = self.keypoint_classifier(pre_processed_landmark_list)
                if hand_sign_id == 2:  # æŒ‡å·®ã—ã‚µã‚¤ãƒ³
                    self.point_history.append(landmark_list[8])  # äººå·®æŒ‡åº§æ¨™
                else:
                    self.point_history.append([0, 0])

                # æç”»
                # debug_image = draw_bounding_rect(self.use_brect, debug_image, brect)
                debug_image = draw_landmarks(debug_image, landmark_list)
        else:
            self.point_history.append([0, 0])

        debug_image = draw_point_history(debug_image, self.point_history)
        return debug_image